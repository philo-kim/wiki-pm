# 데이터 사고의 기초

## 🎯 5분 안에 시작하기

데이터 기반 PM이 되기 위한 첫 걸음입니다. 복잡한 통계 지식 없이도 데이터로 생각하는 법을 익혀보세요.

**바로 시작하기:**
1. 오늘 제품의 핵심 지표 하나를 정의해보세요
2. 그 지표가 왜 중요한지 3가지 이유를 적어보세요
3. 그 지표를 개선하기 위한 가설을 세워보세요

## 📊 데이터 사고란 무엇인가?

### 정의와 본질
데이터 사고는 **가설을 세우고 데이터를 통해 검증하며 의사결정의 근거를 마련하는 사고방식**입니다.

> "Without data, you're just another person with an opinion."  
> — W. Edwards Deming

### PM에게 데이터 사고가 중요한 이유

#### 1. 객관적 의사결정
- 직감이 아닌 근거 기반 결정
- 이해관계자 설득력 향상
- 리스크 최소화

#### 2. 가설 검증 능력
- 빠른 학습과 개선
- 실패 비용 감소
- 지속적 제품 개선

#### 3. 성과 측정과 입증
- 명확한 성공 기준
- ROI 증명
- 팀 성과 가시화

## 🔄 정량적 vs 정성적 데이터

### 정량적 데이터 (Quantitative Data)

#### 특징
- **측정 가능**: 숫자로 표현 가능
- **객관적**: 해석의 여지가 적음
- **규모 파악**: 크기와 빈도 측정

#### 주요 활용 예시
```
📊 제품 지표
- DAU (일일 활성 사용자): 150,000명
- 전환율 (Conversion Rate): 3.5%
- 평균 체류 시간: 8분 32초
- 월간 수익 (MRR): $450,000
- 이탈률 (Churn Rate): 5.2%
```

#### 수집 방법
- **Analytics 도구**: GA4, Mixpanel, Amplitude
- **Database 쿼리**: SQL로 직접 추출
- **A/B 테스트**: 실험을 통한 측정
- **서베이**: 척도형 질문 (1-10점)

#### 장점과 한계
✅ **장점**
- 명확한 측정과 비교
- 트렌드 파악 용이
- 통계적 분석 가능
- 대규모 데이터 처리

❌ **한계**
- "왜"에 대한 답 부족
- 맥락 정보 부재
- 사용자 감정 파악 어려움
- 예상치 못한 인사이트 발견 어려움

### 정성적 데이터 (Qualitative Data)

#### 특징
- **깊이 있는 이해**: 행동의 이유와 맥락
- **주관적 해석**: 다양한 관점 존재
- **풍부한 인사이트**: 예상치 못한 발견

#### 주요 수집 방법

**1. 사용자 인터뷰**
```
💬 인터뷰 질문 예시
- "이 기능을 사용할 때 어떤 점이 불편하셨나요?"
- "왜 경쟁사 제품 대신 우리 제품을 선택하셨나요?"
- "제품을 사용하면서 가장 만족스러운 경험은 무엇이었나요?"
```

**2. 사용성 테스트**
- Think Aloud Protocol
- 태스크 수행 관찰
- 행동 패턴 기록
- 표정과 반응 관찰

**3. 고객 리뷰 분석**
- 앱스토어 리뷰
- 소셜 미디어 멘션
- 고객 지원 티켓
- 커뮤니티 피드백

#### 장점과 한계
✅ **장점**
- 깊은 인사이트
- 맥락 이해
- 개선 아이디어 발굴
- 공감대 형성

❌ **한계**
- 주관적 해석
- 일반화 어려움
- 수집 비용 높음
- 시간 소요 많음

### 정량적 + 정성적 통합 접근

#### 실무 적용 프레임워크
```
1️⃣ 정량적 데이터로 문제 발견
   "전환율이 20% 하락했다"
   ↓
2️⃣ 정성적 데이터로 원인 파악
   "결제 프로세스가 복잡하다는 피드백"
   ↓
3️⃣ 가설 수립
   "결제 단계를 줄이면 전환율이 회복될 것"
   ↓
4️⃣ 정량적 데이터로 검증
   "A/B 테스트 결과 15% 개선"
```

## 🔗 상관관계 vs 인과관계

### 상관관계 (Correlation)

#### 정의
두 변수가 함께 변화하는 관계. 하지만 한 변수가 다른 변수의 원인은 아님.

#### 실무에서 자주 보는 상관관계 함정

**사례 1: 아이스크림과 익사 사고**
```
관찰: 아이스크림 판매량 ↑ = 익사 사고 ↑
착각: 아이스크림이 익사를 유발한다?
진실: 여름(제3의 변수)이 둘 다 증가시킴
```

**사례 2: 앱 사용 시간과 구매액**
```
관찰: 사용 시간 긴 사용자 = 구매액 높음
착각: 사용 시간을 늘리면 구매가 증가한다?
진실: 충성 고객이 둘 다 높을 수 있음
```

### 인과관계 (Causation)

#### 정의
한 변수가 다른 변수의 직접적 원인이 되는 관계.

#### 인과관계 검증 방법

**1. A/B 테스트**
```
✅ 통제된 실험
- 무작위 할당
- 단일 변수 변경
- 충분한 샘플 사이즈
- 통계적 유의성 확인
```

**2. 시간적 선후관계**
```
원인 → 결과의 시간 순서 확인
예: 푸시 알림 발송 → 앱 실행 증가
```

**3. 통제 변수 활용**
```
다른 요인들을 동일하게 유지
예: 같은 시간대, 같은 사용자 그룹, 같은 디바이스
```

### PM이 주의해야 할 인과관계 오류

#### 1. 역인과관계
```
❌ 잘못된 해석: "리뷰가 많으면 판매가 증가한다"
✅ 올바른 해석: "판매가 많아서 리뷰도 많다"
```

#### 2. 허위 상관
```
❌ 잘못된 해석: "닉네임이 긴 사용자가 더 활발하다"
✅ 올바른 해석: 우연의 일치일 가능성
```

#### 3. 제3의 변수
```
❌ 잘못된 해석: "다크모드 사용자의 리텐션이 높다"
✅ 올바른 해석: 파워유저가 다크모드도 쓰고 리텐션도 높음
```

## 🧠 확증 편향 극복하기

### 확증 편향이란?
자신의 믿음을 지지하는 데이터만 선택적으로 보는 경향

### PM이 빠지기 쉬운 확증 편향

#### 1. 성공 지표만 보기
```
❌ 편향된 시각
"신기능 사용률 30% 달성! 성공이다!"

✅ 균형잡힌 시각
"사용률은 30%지만, 재사용률은 5%에 불과하다"
```

#### 2. 유리한 세그먼트만 강조
```
❌ 편향된 시각
"iOS 사용자의 전환율이 10% 증가했다!"

✅ 균형잡힌 시각
"iOS는 증가했지만 Android는 5% 감소했다"
```

### 확증 편향 극복 방법

#### 1. 반대 가설 세우기
```
원 가설: "이 기능이 리텐션을 높일 것이다"
반대 가설: "이 기능이 리텐션에 영향이 없거나 해가 될 것이다"

→ 두 가설 모두 검증
```

#### 2. 다양한 데이터 소스 활용
```
정량적 데이터: 사용률, 전환율, 리텐션
정성적 데이터: 사용자 인터뷰, 리뷰, CS 티켓
경쟁사 데이터: 벤치마크, 시장 트렌드
```

#### 3. 팀원들과 데이터 해석 공유
```
📊 데이터 리뷰 미팅
- 각자 독립적으로 분석
- 다른 해석 가능성 논의
- Devil's Advocate 역할 지정
- 합의된 결론 도출
```

#### 4. 정기적인 가정 재검토
```
월간 가정 검증 체크리스트
□ 우리의 핵심 가정은 여전히 유효한가?
□ 반대 증거는 없는가?
□ 시장 환경이 변했는가?
□ 고객 행동이 바뀌었는가?
```

## 💡 실무 적용 예시

### 넷플릭스: 시청 완료율과 재구독률
```
상관관계 발견: 시청 완료율 ↑ = 재구독률 ↑
가설 수립: 완료율 높은 콘텐츠가 재구독 유도
실험 설계: 개인화 추천으로 완료율 높은 콘텐츠 노출
결과 검증: 재구독률 실제 상승 확인
```

### 스포티파이: 플레이리스트와 리텐션
```
관찰: 플레이리스트 생성자의 리텐션 2배
가설: 플레이리스트 생성이 리텐션 향상 원인
실험: 온보딩에서 플레이리스트 생성 유도
검증: 신규 사용자 리텐션 65% 향상
```

### 에어비앤비: 리뷰와 예약률
```
데이터: 리뷰 많은 숙소의 예약률 높음
심층 분석: 
- 리뷰 수 vs 예약률 (약한 상관)
- 리뷰 품질 vs 예약률 (강한 상관)
- 최근 리뷰 vs 예약률 (매우 강한 상관)
인사이트: 최근 긍정 리뷰가 핵심 요인
```

## 🛠️ PM을 위한 기초 통계 개념

### 꼭 알아야 할 5가지 개념

#### 1. 평균 vs 중앙값
```
상황: 사용 시간 분석
평균: 45분 (소수 헤비유저가 끌어올림)
중앙값: 12분 (일반 사용자의 실제 행동)
→ 중앙값이 더 대표성 있을 수 있음
```

#### 2. 표준편차
```
낮은 표준편차: 사용자 행동이 일관됨
높은 표준편차: 사용자 그룹이 다양함
→ 세그멘테이션 필요성 시사
```

#### 3. 신뢰구간
```
"전환율 3.5% (95% CI: 3.2%-3.8%)"
→ 실제 값이 3.2%-3.8% 사이일 확률 95%
```

#### 4. 통계적 유의성
```
p-value < 0.05: 우연이 아닐 가능성 높음
주의: 통계적 유의성 ≠ 실무적 중요성
```

#### 5. 샘플 사이즈
```
작은 변화 감지 = 큰 샘플 필요
큰 변화 감지 = 작은 샘플도 충분
```

## ✅ 실천 체크리스트

### 일일 데이터 사고 실천
- [ ] 오늘의 핵심 지표 확인
- [ ] 어제 대비 변화 이유 생각해보기
- [ ] 하나의 가설 세우기
- [ ] 검증 방법 계획하기

### 주간 데이터 리뷰
- [ ] 주요 지표 트렌드 분석
- [ ] 정량 + 정성 데이터 통합 해석
- [ ] 상관관계 vs 인과관계 구분
- [ ] 다음 주 실험 계획

### 월간 깊은 분석
- [ ] 확증 편향 체크
- [ ] 핵심 가정 재검토
- [ ] 경쟁사 벤치마크
- [ ] 데이터 인사이트 공유

## 🚀 다음 단계

**입문자**
→ [SQL 기초 배우기](../../resources/tools/sql-guide.md)
→ [Google Analytics 시작하기](../../resources/tools/analytics-tools.md)

**중급자**
→ [코호트 분석 마스터](./cohort-analysis.md)
→ [A/B 테스트 설계](../../3-delivery/experimentation/ab-testing-guide.md)

**고급자**
→ [예측 모델링](../frameworks/predictive-analytics.md)
→ [인과 추론 심화](../frameworks/causal-inference.md)

## 📚 추천 자료

### 도서
- "Lean Analytics" - 스타트업을 위한 데이터 분석
- "Trustworthy Online Controlled Experiments" - A/B 테스트 바이블
- "The Signal and the Noise" - 데이터 해석의 함정

### 온라인 코스
- Google Data Analytics Certificate
- Reforge Data for Product Managers
- Mode Analytics SQL Tutorial

---

*"데이터는 새로운 석유가 아니다. 데이터는 새로운 토양이다."*  
*- David McCandless*